{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Azwadd/CS_448-Artificial-Intelligence/blob/main/Assignment%202/Assignment%202.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Imports section\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature °C</th>\n",
       "      <th>Mols KCL</th>\n",
       "      <th>Size nm^3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>469</td>\n",
       "      <td>647</td>\n",
       "      <td>6.244743e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>403</td>\n",
       "      <td>694</td>\n",
       "      <td>5.779610e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "      <td>975</td>\n",
       "      <td>6.196847e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>779</td>\n",
       "      <td>916</td>\n",
       "      <td>1.460449e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>901</td>\n",
       "      <td>18</td>\n",
       "      <td>4.325726e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>545</td>\n",
       "      <td>637</td>\n",
       "      <td>7.124634e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>660</td>\n",
       "      <td>519</td>\n",
       "      <td>7.006960e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>143</td>\n",
       "      <td>869</td>\n",
       "      <td>2.718260e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>89</td>\n",
       "      <td>461</td>\n",
       "      <td>8.919803e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>294</td>\n",
       "      <td>776</td>\n",
       "      <td>4.770210e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>991</td>\n",
       "      <td>117</td>\n",
       "      <td>2.441771e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>307</td>\n",
       "      <td>781</td>\n",
       "      <td>5.006455e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>206</td>\n",
       "      <td>70</td>\n",
       "      <td>3.145200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>437</td>\n",
       "      <td>599</td>\n",
       "      <td>5.390215e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>566</td>\n",
       "      <td>75</td>\n",
       "      <td>9.185271e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Temperature °C  Mols KCL     Size nm^3\n",
       "0              469       647  6.244743e+05\n",
       "1              403       694  5.779610e+05\n",
       "2              302       975  6.196847e+05\n",
       "3              779       916  1.460449e+06\n",
       "4              901        18  4.325726e+04\n",
       "5              545       637  7.124634e+05\n",
       "6              660       519  7.006960e+05\n",
       "7              143       869  2.718260e+05\n",
       "8               89       461  8.919803e+04\n",
       "9              294       776  4.770210e+05\n",
       "10             991       117  2.441771e+05\n",
       "11             307       781  5.006455e+05\n",
       "12             206        70  3.145200e+04\n",
       "13             437       599  5.390215e+05\n",
       "14             566        75  9.185271e+04"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 1. Loading the dataset\n",
    "# Using pandas load the dataset (load remotely, not locally)\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/profmcnich/example_notebook/main/science_data_large.csv\")\n",
    "\n",
    "# Output the first 15 rows of the data\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature °C      int64\n",
      "Mols KCL            int64\n",
      "Size nm^3         float64\n",
      "dtype: object\n",
      "(1000, 3)\n",
      "(1000,)\n",
      "(1000,)\n",
      "(1000,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Temperature °C  1000 non-null   int64  \n",
      " 1   Mols KCL        1000 non-null   int64  \n",
      " 2   Size nm^3       1000 non-null   float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 23.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the table information (number of data points, etc.)\n",
    "print(data.dtypes)\n",
    "print(data[[\"Temperature °C\", \"Mols KCL\", \"Size nm^3\"]].shape)\n",
    "print(data[\"Temperature °C\"].shape)\n",
    "print(data[\"Mols KCL\"].shape)\n",
    "print(data[\"Size nm^3\"].shape)\n",
    "# Basically the table has 3 columns with 1000 rows each\n",
    "data.info()\n",
    "# Part 1. Loading the dataset - Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Part 2. Splitting the dataset\n",
    "# Take the pandas dataset and split it into our features (X) and label (y)\n",
    "label = np.array(data[\"Size nm^3\"])\n",
    "features = np.array(data[[\"Temperature °C\", \"Mols KCL\"]])\n",
    "\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, label, test_size=0.1, train_size=0.9)\n",
    "# Part 2. Splitting the dataset - Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-416157.45507965]\n",
      "Score: 0.8387535798248023\n",
      "Coefficients: [ 870.7409581  1044.66992793]\n",
      "Intercept: -419117.53589361114\n"
     ]
    }
   ],
   "source": [
    "#Part 3. Perform a Linear Regression\n",
    "# Use sklearn to train a model on the training set\n",
    "lr = LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "# Create a sample datapoint and predict the output of that sample with the trained model\n",
    "print(lr.predict(np.array([[1, 2]])))\n",
    "\n",
    "# Report on the score for that model, in your own words (markdown, not code) explain what the score means\n",
    "print(\"Score:\", lr.score(x_test, y_test))\n",
    "\n",
    "# Extract the coefficients and intercept from the model and write an equation for your h(x) using LaTeX\n",
    "print(\"Coefficients:\", lr.coef_)\n",
    "print(\"Intercept:\", lr.intercept_)\n",
    "#Part 3. Perform a Linear Regression - Completed - report in markdown below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$S = -419117.53589 +  870.74095(a) + 1044.66992(b) $  \n",
    "\n",
    "The linear regression model gave us an 83.87535% accuracy. This means that the linear regression\n",
    "for the data we have is somewhat accurate and there is about a 16.12465% error from the actual\n",
    "data that was obtained from the series of experiments. Essentially, the values from the line\n",
    "of best fit by using the linear regression model is about 16.12465% different from the\n",
    "actual difference when comparing how much temperature °C and Mols KCL creates a change in\n",
    "Size nm^3. This is significant, the fact that the linear regression model for our dataset\n",
    "is not fully accurate is very important because it shows that we still need to improve\n",
    "the training model in order to get a better line of best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72560223 0.82278373 0.87843085 0.83540297 0.84761377 0.82112454]\n"
     ]
    }
   ],
   "source": [
    "# Part 4. Use Cross Validation\n",
    "# Use the cross_val_score function to repeat your experiment across many shuffles of the data\n",
    "print(cross_val_score(lr, x_test, y_test, cv=6))\n",
    "# Report on their finding and their significance\n",
    "# Part 4. Use Cross Validation - Completed - report in markdown below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The 6 cross validation scores show us that the accuracy is around 72%-88%, which shows that the\n",
    "linear regression model used is accurate but not completely accurate. The 72%-88% accuracy range shows that the accuracy has a large range of 16% in between the accuracies. In fact the 72%-88% accuracy range, also shows that the model being used will not be completely accurate in any scenario that was tested. This fact that the model won't be 100% accurate is significant \n",
    "because it leads us to assume that we need to improve the accuracy. To improve the accuracy maybe we should try another model or something to help the model in order to improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Intercept: 1.7255311831831932e-05\n",
      "Coefficients: [ 0.00000000e+00  1.20000000e+01 -1.37042472e-07 -2.12005968e-11\n",
      "  2.00000000e+00  2.85714287e-02]\n",
      "Predict:  [36.20001687]\n"
     ]
    }
   ],
   "source": [
    "# Part 5. Using Polynomial Regression\n",
    "# Using the PolynomialFeatures library perform another regression on an augmented dataset of degree 2\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train = poly.fit_transform(x_train)\n",
    "X_test = poly.fit_transform(x_test)\n",
    "reg = linear_model.BayesianRidge()\n",
    "reg.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", reg.score(X_test, y_test))\n",
    "print(\"Intercept:\", reg.intercept_)\n",
    "print(\"Coefficients:\", reg.coef_) # we get 6 coefficients\n",
    "print(\"Predict: \", reg.predict(np.array([[1, 2, 3, 5, 6, 7]]))) # 6 predict because 6 coefficients\n",
    "# Report on the metrics and output the resultant equation as you did in Part 3.\n",
    "# Part 5. Using Polynomial Regression - Completed - report in markdown below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = 1.72553(10^{-5}) + 0(1) + 1.2(10^2)(a) - 1.37042472e(10^{-7})(b) - 2.12005(10^{-11})(a^2) + 2(ab) + 2.85714(10^{-2})(b^2)$\n",
    "\n",
    "The model scored 100% meaning that the polynomialfeatures with the bayesian ridge regresson model is fully accurate.\n",
    "This is significant because it means that the previous model used linear regression is not capable of getting a fully accurate line of best fit by itself. The addition of polynomialfeatures gave a huge benefit and allowed the bayesian ridge model to gain enough accuracy to gain the score of 100% accuracy. This is significant because it shows that utilizing polynomialfeatures is really beneficial because we can use a multitude of degrees and fit it into a new array that is easier for the linear model to fit into. Therefore, the results show that polynomial regression is great because you can get high accuracy rates with polynomialfeatures and any compatible linear model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
