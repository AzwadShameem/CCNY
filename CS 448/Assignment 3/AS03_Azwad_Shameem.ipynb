{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/Azwadd/CS_448-Artificial-Intelligence/blob/main/Assignment%203/AS03_Azwad_Shameem.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [],
   "source": [
    "# Part 1: Load the dataset\n",
    "# Load the dataset (load remotely, not locally)\n",
    "iris = load_iris(as_frame=True) # This one is used only to display summary\n",
    "results = [] # this list will be used to store the results to be shown in a table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [
    {
     "data": {
      "text/plain": "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n0                 5.1               3.5                1.4               0.2\n1                 4.9               3.0                1.4               0.2\n2                 4.7               3.2                1.3               0.2\n3                 4.6               3.1                1.5               0.2\n4                 5.0               3.6                1.4               0.2\n5                 5.4               3.9                1.7               0.4\n6                 4.6               3.4                1.4               0.3\n7                 5.0               3.4                1.5               0.2\n8                 4.4               2.9                1.4               0.2\n9                 4.9               3.1                1.5               0.1\n10                5.4               3.7                1.5               0.2\n11                4.8               3.4                1.6               0.2\n12                4.8               3.0                1.4               0.1\n13                4.3               3.0                1.1               0.1\n14                5.8               4.0                1.2               0.2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5.4</td>\n      <td>3.9</td>\n      <td>1.7</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4.6</td>\n      <td>3.4</td>\n      <td>1.4</td>\n      <td>0.3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>5.0</td>\n      <td>3.4</td>\n      <td>1.5</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4.4</td>\n      <td>2.9</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4.9</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>5.4</td>\n      <td>3.7</td>\n      <td>1.5</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>4.8</td>\n      <td>3.4</td>\n      <td>1.6</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>4.8</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4.3</td>\n      <td>3.0</td>\n      <td>1.1</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>5.8</td>\n      <td>4.0</td>\n      <td>1.2</td>\n      <td>0.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the first 15 rows of the data\n",
    "iris['data'].head(15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [
    {
     "data": {
      "text/plain": "    target\n0        0\n1        0\n2        0\n3        0\n4        0\n5        0\n6        0\n7        0\n8        0\n9        0\n10       0\n11       0\n12       0\n13       0\n14       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the first 15 rows of the data\n",
    "pd.DataFrame(iris['target']).head(15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Shape of Feature names (4, 1)\n",
      "Shape of Features (150, 4)\n",
      "Label names ['setosa' 'versicolor' 'virginica']\n",
      "Shape of Label names (3, 1)\n",
      "Shape of Labels (150,)\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "print(\"Feature names\", iris['feature_names'])\n",
    "print(\"Shape of Feature names\", pd.DataFrame(iris['feature_names']).shape)\n",
    "print(\"Shape of Features\", iris['data'].shape)\n",
    "print(\"Label names\", iris['target_names'])\n",
    "print(\"Shape of Label names\", pd.DataFrame(iris['target_names']).shape)\n",
    "print(\"Shape of Labels\", iris['target'].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Explain what the data is in your own words. What are your features and labels?\n",
    "What is the mapping of your labels to the actual classes?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [],
   "source": [
    "# Part 2: Split the dataset into train and test\n",
    "# Take the dataset and split it into our features (X) and label (y)\n",
    "features, labels = load_iris(return_X_y=True) # this loads as features and labels for us\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, train_size=.9, test_size=.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for class 0: [[9.79527812e-01 2.04721654e-02 2.29567722e-08]] --> Highest probability should be the first one\n",
      "Prediction for class 1: [[0.00278053 0.86466762 0.13255186]] --> Highest probability should be the second one\n",
      "Prediction for class 2: [[1.58185286e-06 5.12841903e-03 9.94869999e-01]] --> Highest probability should be the third one\n",
      "Train Accuracy: 0.9703703703703703\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Part 3: Logistic Regression\n",
    "# i. Use sklearn to train a LogisticRegression model on the training set\n",
    "lr = LogisticRegression().fit(x_train, y_train)\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "print(\"Prediction for class 0:\", lr.predict_proba([[5.1, 3.5, 1.4, 0.2]]), \"--> Highest probability should be the first one\")\n",
    "print(\"Prediction for class 1:\", lr.predict_proba([[7.0, 3.2, 4.7, 1.4]]), \"--> Highest probability should be the second one\")\n",
    "print(\"Prediction for class 2:\", lr.predict_proba([[6.3, 3.3, 6.0, 2.5]]), \"--> Highest probability should be the third one\")\n",
    "# iii. Report on the score for Logistic regression model, what does the score measure?\n",
    "results.append(lr.score(x_train, y_train))\n",
    "print(\"Train Accuracy:\", results[len(results)-1])\n",
    "results.append(lr.score(x_test, y_test))\n",
    "print(\"Test Accuracy:\", results[len(results)-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The train accuracy is about 97% and the test accuracy is 100%, this seems like the model has underfit in this simulation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [  9.54117522   2.49328079 -12.03445601]\n",
      "Coefficients: [[-0.39999741  0.93481451 -2.44269122 -1.03806968]\n",
      " [ 0.46124372 -0.32078229 -0.18813799 -0.9091972 ]\n",
      " [-0.06124631 -0.61403221  2.63082921  1.94726688]]\n"
     ]
    }
   ],
   "source": [
    "# iv. Extract the coefficents and intercepts for the boundary line(s)\n",
    "print(\"Intercept:\", lr.intercept_)\n",
    "print(\"Coefficients:\", lr.coef_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for class 0: [[0.9747327  0.01579445 0.00947285]] --> Highest probability should be the first one\n",
      "Prediction for class 1: [[0.01233575 0.86211959 0.12554466]] --> Highest probability should be the second one\n",
      "Prediction for class 2: [[0.00708249 0.00105843 0.99185908]] --> Highest probability should be the third one\n",
      "Train Accuracy: 0.9481481481481482\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Part 4: Support Vector Machine\n",
    "# i. Use sklearn to train a Support Vector Classifier on the training set\n",
    "svm1 = svm.SVC(probability=True).fit(x_train, y_train)\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "print(\"Prediction for class 0:\", svm1.predict_proba([[5.1, 3.5, 1.4, 0.2]]), \"--> Highest probability should be the first one\")\n",
    "print(\"Prediction for class 1:\", svm1.predict_proba([[7.0, 3.2, 4.7, 1.4]]), \"--> Highest probability should be the second one\")\n",
    "print(\"Prediction for class 2:\", svm1.predict_proba([[6.3, 3.3, 6.0, 2.5]]), \"--> Highest probability should be the third one\")\n",
    "# iii. Report on the score for the SVM, what does the score measure?\n",
    "results.append(svm1.score(x_train, y_train))\n",
    "print(\"Train Accuracy:\", results[len(results)-1])\n",
    "results.append(svm1.score(x_test, y_test))\n",
    "print(\"Test Accuracy:\", results[len(results)-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The particular scores of the predict_proba mean how accurately can the model\n",
    "predict if a datapoint for class 0, 1, 2 is given. Take for example\n",
    "the prediction for class 0, the first one is 97.47% while the rest 1.15% and 0.94%.\n",
    "Clearly, the model is able to predict that the particular datapoint is\n",
    "class 0 with a 97.47% probaility of it being correct.\n",
    "\n",
    "Also the scores of the svm is 94.81% for train accuracy and 100% for test\n",
    "accuarcy. This shows sign of underfitting because there is a sizeable difference\n",
    "between how high the test accuracy is compared to the train accuracy."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for class 0: [[9.99714400e-01 2.85599795e-04 2.34326735e-10]] --> Highest probability should be the first one\n",
      "Prediction for class 1: [[2.85822396e-04 9.97143432e-01 2.57074518e-03]] --> Highest probability should be the second one\n",
      "Prediction for class 2: [[5.15193213e-08 1.63191435e-04 9.99836757e-01]] --> Highest probability should be the third one\n",
      "\n",
      "default:\n",
      "Train Accuracy: 0.9703703703703703\n",
      "Test Accuracy: 1.0 \n",
      "\n",
      "identity:\n",
      "Train Accuracy: 0.9777777777777777\n",
      "Test Accuracy: 1.0 \n",
      "\n",
      "tanh:\n",
      "Train Accuracy: 0.9777777777777777\n",
      "Test Accuracy: 1.0 \n",
      "\n",
      "logistic:\n",
      "Train Accuracy: 0.9851851851851852\n",
      "Test Accuracy: 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 5: Neural Network\n",
    "# i. Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
    "mpc = MLPClassifier(max_iter=600).fit(x_train, y_train) # used max-iter to remove non convergence warning\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "print(\"Prediction for class 0:\", mpc.predict_proba([[5.1, 3.5, 1.4, 0.2]]), \"--> Highest probability should be the first one\")\n",
    "print(\"Prediction for class 1:\", mpc.predict_proba([[7.0, 3.2, 4.7, 1.4]]), \"--> Highest probability should be the second one\")\n",
    "print(\"Prediction for class 2:\", mpc.predict_proba([[6.3, 3.3, 6.0, 2.5]]), \"--> Highest probability should be the third one\\n\")\n",
    "# iii. Report on the score for the Neural Network, what does the score measure?\n",
    "print(\"default:\") # note the default is actually 'relu'\n",
    "results.append(mpc.score(x_train, y_train))\n",
    "print(\"Train Accuracy:\", results[len(results)-1])\n",
    "results.append(mpc.score(x_test, y_test))\n",
    "print(\"Test Accuracy:\", results[len(results)-1], \"\\n\")\n",
    "\n",
    "# iv: Experiment with different options for the neural network, report on your best configuration (the highest score I was able to achieve was 0.8666)\n",
    "for i in [\"identity\", \"tanh\", \"logistic\"]:\n",
    "    print(i + \":\")\n",
    "    mpc = MLPClassifier(activation=i, max_iter=900).fit(x_train, y_train) # used max-iter to remove non convergence warning\n",
    "    results.append(mpc.score(x_train, y_train))\n",
    "    print(\"Train Accuracy:\", results[len(results)-1])\n",
    "    results.append(mpc.score(x_test, y_test))\n",
    "    print(\"Test Accuracy:\", results[len(results)-1], \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best score was with the logistic activation function with the max_iter=900.\n",
    "Utilizing the configuration of different max_iters, we realized that depending\n",
    "on the iteration the accuracy may increase or even decreaase. The highest\n",
    "accuracy I achieved was when I used max_iter=900 and I believe this is\n",
    "cloest iteration to convergence that I was able to test and as a result\n",
    "gave a higher score. Furthermore not utilizing max_iter gave an warning\n",
    "statement that the Neural Network did not converge which is why\n",
    "there is a max_iter listed for every activation function of MLPClassifier."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for class 0: [[1. 0. 0.]] --> Highest probability should be the first one\n",
      "Prediction for class 1: [[0. 1. 0.]] --> Highest probability should be the second one\n",
      "Prediction for class 2: [[0. 0. 1.]] --> Highest probability should be the third one\n",
      "\n",
      "Train Accuracy: 0.9703703703703703\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Part 6 : K-Nearest Neighbors\n",
    "# i. Use sklearn to 'train' a k-Neighbors Classifier\n",
    "neighbors = KNeighborsClassifier().fit(x_train, y_train)\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "print(\"Prediction for class 0:\", neighbors.predict_proba([[5.1, 3.5, 1.4, 0.2]]), \"--> Highest probability should be the first one\")\n",
    "print(\"Prediction for class 1:\", neighbors.predict_proba([[7.0, 3.2, 4.7, 1.4]]), \"--> Highest probability should be the second one\")\n",
    "print(\"Prediction for class 2:\", neighbors.predict_proba([[6.3, 3.3, 6.0, 2.5]]), \"--> Highest probability should be the third one\\n\")\n",
    "# iii. Report on the score for kNN, what does the score measure?\n",
    "results.append(neighbors.score(x_train, y_train))\n",
    "print(\"Train Accuracy:\", results[len(results)-1])\n",
    "results.append(neighbors.score(x_test, y_test))\n",
    "print(\"Test Accuracy:\", results[len(results)-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The K-Nearest Neighbors algorithm was suprisingly able to give us a prediction\n",
    "of a datapoint with 100% accuracy with datapoints for every class. This shows\n",
    "that the K-Nearest Neighbors is very accurate at predicting datapoints correlating\n",
    "to specific classes. \n",
    "\n",
    "The scores fo K-Nearest Neighbors are 97.03% train accuracy and 100% test accuracy. \n",
    "There is slight underfitting because the train accuracy is less than the test accuracy\n",
    "but not too much since 3% difference is minimal. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1400x300 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Putting The Data Into A Table\n",
    "fig, ax = plt.subplots(dpi=200, figsize = (7,1.5))\n",
    "fig.patch.set_visible(False)\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "cases=np.array([\"Train Accuracy\", \"Test Accuracy\"])\n",
    "df = pd.DataFrame({\"Logistic Regression\" : results[0:2:],\n",
    "                   \"SVM\" : results[2:4:],\n",
    "                   \"Neural Network (default)\" : results[4:6:],\n",
    "                   \"Neural Network (identity)\" : results[6:8:],\n",
    "                   \"Neural Network (tanh)\" : results[8:10:],\n",
    "                   \"Neural Network (logistic)\" : results[10:12:],\n",
    "                   \"KNeighbors Classifier\" : results[12:14:],\n",
    "                   })\n",
    "ax.table(cellText=df.values, rowLabels=cases, colLabels=df.columns, cellLoc='center', loc='center')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: The table above shows the data for each model for your convenience\n",
    "\n",
    "Part 7: Conclusions and takeaways.\n",
    "Considering test and train accuracies the model with the highest accuracy is the Neural Network using the\n",
    "logistic activation function with a train accuracy of 98.5% and a 100% test accuracy. For the runnersup there is a two way tie\n",
    "with the identity and 'tanh' neural networks coming in with a train accuracy of 97.77% and a 100% test accuracy.\n",
    "For 3rd place we have a 3 way tie betweeen Logistic Regression, Neural Network(default) and\n",
    "the KNeighbors Classifier coming in a train accuracy of 97.03% and a test accuracy of 100%.\n",
    "In last place we have the Support Vector Machine with a train accuracy of 94.81% and\n",
    "a test accuracy of 100%.\n",
    "\n",
    "I believe the Neural Network using activation='logistic' performed the best because\n",
    "this particular dataset slightly is more aligned to this specific model. The difference\n",
    "between the accuracies of each model is very close so it is difficult to say exactly why\n",
    "one model will always perform better than the other for a particular split of the dataset.\n",
    "If this same simulation were to be ran again with the same dataset and procedure,\n",
    "any model has a chance of performing the best because the way the dataset is randomly split\n",
    "can inadvertedly benefit one model over the other. If the accuracies were more drastically\n",
    "different than we can come with conclusions saying one model is better than the other\n",
    "but since the accuracies are so close we are unable to. As a result, the only thing we can\n",
    "say for certainty is that in this particular simulation the algorithm from the Neural Network\n",
    "using logistic activation benefited the most.\n",
    "\n",
    "Suprisingly all the models had a 100% test accuracy, interestingly the data was split in a away that all the models\n",
    "had full test accuracy. However, no model recieved 100% test accuracy. This leads us to believe there was some\n",
    "underfitting. Clearly, the Support Vector Machine had the highest underfitting occuring\n",
    "because there is a 6% gap between train and test accuracies. The other models\n",
    "have a range of 2-3% differences in accuracies which shows there is some slight\n",
    "underfitting in this particular simulation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
